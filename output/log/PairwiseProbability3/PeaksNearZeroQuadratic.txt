Optimal points: [0.3 0.15 0.12; 0.1 0.12 0.21; 0.2 0.3 0.2]
Starting allocation: [0.167994439276539, 0.2340111214469219, 0.167994439276539]

=== Round 1 ===
Current report matrix:
3×3 Matrix{Float64}:
 0.3  0.15  0.12
 0.1  0.12  0.21
 0.2  0.3   0.2
Current allocation: [0.167994439276539, 0.2340111214469219, 0.167994439276539]
Voter 1's turn.
  Best response = [0.279323257042888, 0.17248750586856085, 0.08976170301283017]
  New allocation: [0.1596160749834417, 0.2223403159573955, 0.1596160749834417]
  => Voter 1 improves by switching to best response
  Old utility = 0.788914083607926
  New utility = 0.7910937658552867
  Honest utility = 0.788914083607926
  Incentive Alignment = 0.985672209505117
Voter 2's turn.
  Best response = [0.125, 0.12, 0.21]
  New allocation: [0.19475929973048128, 0.18877846645143972, 0.15803469974235795]
  => Voter 2 improves by switching to best response
  Old utility = 0.7581582982954006
  New utility = 0.7604351129388337
  Honest utility = 0.7581582982954006
  Incentive Alignment = 0.9773388761717837
Voter 3's turn.
  => No improvement found; voter 3 stays with old report.
  Old utility = 0.9167130535886909
  New utility = 0.9167130535886909
  Honest utility = 0.9167130535886909
  Incentive Alignment = 0.9773388761717837

=== Round 2 ===
Current report matrix:
3×3 Matrix{Float64}:
 0.279323  0.172488  0.0897617
 0.125     0.12      0.21
 0.2       0.3       0.2
Current allocation: [0.19475929973048128, 0.18877846645143972, 0.15803469974235795]
Voter 1's turn.
  Best response = [0.2528454188866194, 0.19764131424790954, 0.13046439166860924]
  New allocation: [0.20892058101807987, 0.2025048711374283, 0.16952567264762997]
  => Voter 1 improves by switching to best response
  Old utility = 0.8894719240501542
  New utility = 0.8935775074354426
  Honest utility = 0.8932599878701395
  Incentive Alignment = 0.9690521363420169
Voter 2's turn.
  => No improvement found; voter 2 stays with old report.
  Old utility = 0.7035194466372765
  New utility = 0.7035194466372765
  Honest utility = 0.6989747160895275
  Incentive Alignment = 0.9690521363420169
Voter 3's turn.
  => No improvement found; voter 3 stays with old report.
  Old utility = 0.9381555203222999
  New utility = 0.9381555203222999
  Honest utility = 0.9381555203222999
  Incentive Alignment = 0.9690521363420169

=== Round 3 ===
Current report matrix:
3×3 Matrix{Float64}:
 0.252845  0.197641  0.130464
 0.125     0.12      0.21
 0.2       0.3       0.2
Current allocation: [0.20892058101807987, 0.2025048711374283, 0.16952567264762997]
Voter 1's turn.
  => No improvement found; voter 1 stays with old report.
  Old utility = 0.8935775074354426
  New utility = 0.8935775074354426
  Honest utility = 0.8932599878701395
  Incentive Alignment = 0.9690521363420169
Voter 2's turn.
  => No improvement found; voter 2 stays with old report.
  Old utility = 0.7035194466372765
  New utility = 0.7035194466372765
  Honest utility = 0.6989747160895275
  Incentive Alignment = 0.9690521363420169
Voter 3's turn.
  => No improvement found; voter 3 stays with old report.
  Old utility = 0.9381555203222999
  New utility = 0.9381555203222999
  Honest utility = 0.9381555203222999
  Incentive Alignment = 0.9690521363420169
Converged! Maximum improvement in utility < 0.0001.
Final reports:
3×3 Matrix{Float64}:
 0.252845  0.197641  0.130464
 0.125     0.12      0.21
 0.2       0.3       0.2
Final Allocation: [0.20892058101807987, 0.2025048711374283, 0.16952567264762997]
Mean Utility: 0.845084158131673
Optimality: 0.845084158131673
Envy: 23.463607368502338
Incentive Alignment: 0.9690521363420169
