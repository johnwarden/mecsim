Optimal points: [0.9779951100244499 0.022004889975550123; 0.058823529411764705 0.9411764705882353]
Starting allocation: [0.5, 0.5]

=== Round 1 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.977995   0.0220049
 0.0588235  0.941176
Current allocation: [0.5, 0.5]
Voter 1's turn.
  Best response = [0.29249860447120124, 0.030001402537655066]
  New allocation: [0.3306250017522141, 0.3306250017522141]
  => Voter 1 improves by switching to best response
  Old utility = 0.8041761414663255
  New utility = 0.8214352581012297
  Honest utility = 0.8041761414663255
  Incentive Alignment = 0.6572284276158278
Voter 2's turn.
  Best response = [0.2503899616074592, 0.9896101539346777]
  New allocation: [0.39062503063774834, 0.39062503063774834]
  => Voter 2 improves by switching to best response
  Old utility = 0.8616078080893901
  New utility = 0.8640331641919357
  Honest utility = 0.8616078080893901
  Incentive Alignment = 0.5584312621368893

=== Round 2 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.292499  0.0300014
 0.25039   0.98961
Current allocation: [0.39062503063774834, 0.39062503063774834]
Voter 1's turn.
  Best response = [0.06188000654911492, 0.02061987825448394]
  New allocation: [0.330625000086434, 0.330625000086434]
  => Voter 1 improves by switching to best response
  Old utility = 0.8189629147951557
  New utility = 0.8214352581012296
  Honest utility = 0.8041761414663255
  Incentive Alignment = 0.4431447593075873
Voter 2's turn.
  Best response = [0.5627234244552513, 0.9172767640213338]
  New allocation: [0.390625018320046, 0.390625018320046]
  => Voter 2 improves by switching to best response
  Old utility = 0.8616078079488645
  New utility = 0.864033164191936
  Honest utility = 0.8533813591315054
  Incentive Alignment = 0.2897087488367607

=== Round 3 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.06188   0.0206199
 0.562723  0.917277
Current allocation: [0.390625018320046, 0.390625018320046]
Voter 1's turn.
  Best response = [1.6599900952694263e-6, 1.6030674426163247e-7]
  New allocation: [0.3700005021933561, 0.3700005021933561]
  => Voter 1 improves by switching to best response
  Old utility = 0.81896291576967
  New utility = 0.8203401727926308
  Honest utility = 0.8041761414663255
  Incentive Alignment = 0.25864633878154947
Voter 2's turn.
  Best response = [0.6670395480709713, 0.8954586643143255]
  New allocation: [0.3906250081705341, 0.3906250081705341]
  => Voter 2 improves by switching to best response
  Old utility = 0.8637618445303479
  New utility = 0.8640331641919362
  Honest utility = 0.8488747979986223
  Incentive Alignment = 0.20591359730604103

=== Round 4 ===
Current report matrix:
2×2 Matrix{Float64}:
 1.65999e-6  1.60307e-7
 0.66704     0.895459
Current allocation: [0.3906250081705341, 0.3906250081705341]
Voter 1's turn.
  => No improvement found; voter 1 stays with old report.
  Old utility = 0.8189629165726476
  New utility = 0.8189629273365987
  Honest utility = 0.8041761414663255
  Incentive Alignment = 0.20591359730604103
Voter 2's turn.
  => No improvement found; voter 2 stays with old report.
  Old utility = 0.8640331641919362
  New utility = 0.8640331641919362
  Honest utility = 0.8488747979986223
  Incentive Alignment = 0.20591359730604103
Converged! Maximum improvement in utility < 0.0001.
Final reports:
2×2 Matrix{Float64}:
 1.65999e-6  1.60307e-7
 0.66704     0.895459
Final Allocation: [0.3906250081705341, 0.3906250081705341]
Mean Utility: 0.8414980403822919
Optimality: 0.8414980403822919
Envy: 4.507024761928857
Incentive Alignment: 0.20591359730604103
