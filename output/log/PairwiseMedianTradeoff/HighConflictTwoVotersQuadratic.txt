Optimal points: [0.8 0.1; 0.1 0.5]
Starting allocation: [0.3854247166457143, 0.3645752833542857]

=== Round 1 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.8  0.1
 0.1  0.5
Current allocation: [0.3854247166457143, 0.3645752833542857]
Voter 1's turn.
  Best response = [0.9999769036030759, 6.055454452532249e-6]
  New allocation: [0.43356223207713185, 0.3664292474516323]
  => Voter 1 improves by switching to best response
  Old utility = 0.6278880828764818
  New utility = 0.684213566680097
  Honest utility = 0.6278880828764818
  Incentive Alignment = 0.8882082841615132
Voter 2's turn.
  Best response = [5.6606855327148386e-9, 0.2001247851018419]
  New allocation: [0.3000260332830543, 0.3000278416269736]
  => Voter 2 improves by switching to best response
  Old utility = 0.5034426592130168
  New utility = 0.6923104687872296
  Honest utility = 0.5034426592130168
  Incentive Alignment = 0.7301535915879618

=== Round 2 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.999977    6.05545e-6
 5.66069e-9  0.200125
Current allocation: [0.3000260332830543, 0.3000278416269736]
Voter 1's turn.
  => No improvement found; voter 1 stays with old report.
  Old utility = 0.5538690695067335
  New utility = 0.553869835398899
  Honest utility = 0.49514501829336116
  Incentive Alignment = 0.7301535915879618
Voter 2's turn.
  => No improvement found; voter 2 stays with old report.
  Old utility = 0.6923104687872296
  New utility = 0.6923104795922579
  Honest utility = 0.5034426592130168
  Incentive Alignment = 0.7301535915879618
Converged! Maximum improvement in utility < 0.0001.
Final reports:
2×2 Matrix{Float64}:
 0.999977    6.05545e-6
 5.66069e-9  0.200125
Final Allocation: [0.3000260332830543, 0.3000278416269736]
Mean Utility: 0.6230897691469816
Optimality: 0.6230897691469816
Envy: 13.844139928049604
Incentive Alignment: 0.7301535915879618
