Optimal points: [0.09 0.0225 0.0144; 0.010000000000000002 0.0144 0.0121; 0.04000000000000001 0.09 0.010000000000000002]
Starting allocation: [0.04723263184471401, 0.049252107876743535, 0.030415260278542442]

=== Round 1 ===
Current report matrix:
3×3 Matrix{Float64}:
 0.09  0.0225  0.0144
 0.01  0.0144  0.0121
 0.04  0.09    0.01
Current allocation: [0.04723263184471401, 0.049252107876743535, 0.030415260278542442]
Voter 1's turn.
  Best response = [0.05617461789369449, 0.04823263396225834, 0.008138167391245277]
  New allocation: [0.04315704624124231, 0.05028171788270331, 0.019106655123252488]
  => Voter 1 improves by switching to best response
  Old utility = 0.986718251261044
  New utility = 0.9872618857223312
  Honest utility = 0.986718251261044
  Incentive Alignment = 0.985680101362505
Voter 2's turn.
  Best response = [0.010000000000000002, 0.02513333333333333, 0.0121]
  New allocation: [0.03939250247606709, 0.05387788467939779, 0.019275032091733212]
  => Voter 2 improves by switching to best response
  Old utility = 0.9775490932146813
  New utility = 0.9777145539094722
  Honest utility = 0.9775490932146813
  Incentive Alignment = 0.9821023235847272
Voter 3's turn.
  Best response = [0.05586169844774044, 0.17540763517110788, 0.0062189899357948455]
  New allocation: [0.03980872524984827, 0.05576391913706571, 0.016972774860284118]
  => Voter 3 improves by switching to best response
  Old utility = 0.9946327454961915
  New utility = 0.9956186920152867
  Honest utility = 0.9946327454961915
  Incentive Alignment = 0.9531188921870135

=== Round 2 ===
Current report matrix:
3×3 Matrix{Float64}:
 0.0561746  0.0482326  0.00813817
 0.01       0.0251333  0.0121
 0.0558617  0.175408   0.00621899
Current allocation: [0.03980872524984827, 0.05576391913706571, 0.016972774860284118]
Voter 1's turn.
  Best response = [0.09827962035155319, 0.004278510264440221, 0.007800470252485617]
  New allocation: [0.038895519079158364, 0.048940832469010084, 0.02252224932031058]
  => Voter 1 improves by switching to best response
  Old utility = 0.9843620420902494
  New utility = 0.9853213246837695
  Honest utility = 0.984408391476774
  Incentive Alignment = 0.9604140045941724
Voter 2's turn.
  Best response = [0.0033663493440855563, 0.018996033493383177, 0.05361134169503612]
  New allocation: [0.03848246955601702, 0.04095591631843292, 0.030920214994029076]
  => Voter 2 improves by switching to best response
  Old utility = 0.9794460059194614
  New utility = 0.9803478819561819
  Honest utility = 0.9795707728322414
  Incentive Alignment = 0.9498956034798649
Voter 3's turn.
  Best response = [0.056814860638160825, 0.3360573580080264, 0.0005360593098369271]
  New allocation: [0.0362586497543693, 0.04292591193259474, 0.031174039181514977]
  => Voter 3 improves by switching to best response
  Old utility = 0.9865814862036829
  New utility = 0.9872210310326823
  Honest utility = 0.9847998593247993
  Incentive Alignment = 0.8966081211963092

=== Round 3 ===
Current report matrix:
3×3 Matrix{Float64}:
 0.0982796   0.00427851  0.00780047
 0.00336635  0.018996    0.0536113
 0.0568149   0.336057    0.000536059
Current allocation: [0.0362586497543693, 0.04292591193259474, 0.031174039181514977]
Voter 1's turn.
  Best response = [0.10859149374402612, 0.0002643109621368763, 0.0009205097041159005]
  New allocation: [0.03770507040968321, 0.040927706025791495, 0.031143537974804198]
  => Voter 1 improves by switching to best response
  Old utility = 0.983602931945507
  New utility = 0.9848046093966041
  Honest utility = 0.9808159025302456
  Incentive Alignment = 0.8929778816679844
Voter 2's turn.
  => No improvement found; voter 2 stays with old report.
  Old utility = 0.9806437778258615
  New utility = 0.9806587033763133
  Honest utility = 0.9792931649262581
  Incentive Alignment = 0.8929778816679844
Voter 3's turn.
  => No improvement found; voter 3 stays with old report.
  Old utility = 0.9864679877228428
  New utility = 0.9864818307453526
  Honest utility = 0.9829159240185763
  Incentive Alignment = 0.8929778816679844

=== Round 4 ===
Current report matrix:
3×3 Matrix{Float64}:
 0.108591    0.000264311  0.00092051
 0.00336635  0.018996     0.0536113
 0.0568149   0.336057     0.000536059
Current allocation: [0.03770507040968321, 0.040927706025791495, 0.031143537974804198]
Voter 1's turn.
  => No improvement found; voter 1 stays with old report.
  Old utility = 0.9848046093966041
  New utility = 0.9848046093966041
  Honest utility = 0.9808159025302456
  Incentive Alignment = 0.8929778816679844
Voter 2's turn.
  => No improvement found; voter 2 stays with old report.
  Old utility = 0.9806437778258615
  New utility = 0.9806587033763133
  Honest utility = 0.9792931649262581
  Incentive Alignment = 0.8929778816679844
Voter 3's turn.
  => No improvement found; voter 3 stays with old report.
  Old utility = 0.9864679877228428
  New utility = 0.9864818307453526
  Honest utility = 0.9829159240185763
  Incentive Alignment = 0.8929778816679844
Converged! Maximum improvement in utility < 0.0001.
Final reports:
3×3 Matrix{Float64}:
 0.108591    0.000264311  0.00092051
 0.00336635  0.018996     0.0536113
 0.0568149   0.336057     0.000536059
Final Allocation: [0.03770507040968321, 0.040927706025791495, 0.031143537974804198]
Mean Utility: 0.9839721249817694
Optimality: 0.9839721249817694
Envy: 0.5824209896981292
Incentive Alignment: 0.8929778816679844
