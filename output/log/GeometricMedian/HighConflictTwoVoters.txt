Optional points: [0.9615384615384615 0.038461538461538436; 0.1 0.9]
Starting allocation: [0.5307692307692308, 0.4692307692307692]

=== Round 1 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.961538  0.0384615
 0.1       0.9
Current allocation: [0.5307692307692308, 0.4692307692307692]
Voter 1's turn.
  Best response = [0.9999998899520147, 4.217125496948205e-8]
  New allocation: [0.5499999449760073, 0.4500000210856275]
  => Voter 1 improves by switching to best response
  Old utility = 0.8487317484738964
  New utility = 0.8587767619549314
  Honest utility = 0.8487317484738964
  Incentive Alignment = 0.9728036391565968
Voter 2's turn.
  Best response = [1.1883109104956927e-7, 0.9999998966333525]
  New allocation: [0.500000004391553, 0.49999996940230373]
  => Voter 2 improves by switching to best response
  Old utility = 0.8709168942376995
  New utility = 0.8944271714563381
  Honest utility = 0.8709168942376995
  Incentive Alignment = 0.9020930395967057

=== Round 2 ===
Current report matrix:
2×2 Matrix{Float64}:
 1.0         4.21713e-8
 1.18831e-7  1.0
Current allocation: [0.500000004391553, 0.49999996940230373]
Voter 1's turn.
  => No improvement found; voter 1 stays with old report.
  Old utility = 0.8320502931397008
  New utility = 0.8320502944477166
  Honest utility = 0.8212271142602942
  Incentive Alignment = 0.9020930395967057
Voter 2's turn.
  => No improvement found; voter 2 stays with old report.
  Old utility = 0.8944271714563381
  New utility = 0.8944271714563381
  Honest utility = 0.8709168942376995
  Incentive Alignment = 0.9020930395967057
Converged! Maximum improvement in utility < 0.0001.
Final reports:
2×2 Matrix{Float64}:
 1.0         4.21713e-8
 1.18831e-7  1.0
Final Allocation: [0.500000004391553, 0.49999996940230373]
Mean Utility: 0.8632387322980195
Optimality: 0.8632387322980195
Envy: 6.237687831663729
Incentive Alignment: 0.9020930395967057
