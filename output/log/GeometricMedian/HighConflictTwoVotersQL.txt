Optimal points: [0.9779951100244499 0.022004889975550123; 0.058823529411764705 0.9411764705882353]
Starting allocation: [0.5184093197181073, 0.48159068028189267]

=== Round 1 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.977995   0.0220049
 0.0588235  0.941176
Current allocation: [0.5184093197181073, 0.48159068028189267]
Voter 1's turn.
  Best response = [0.9999998671929344, 2.8996263106218625e-8]
  New allocation: [0.5294116983023496, 0.47058824979224917]
  => Voter 1 improves by switching to best response
  Old utility = 0.814984005200268
  New utility = 0.8213175826864395
  Honest utility = 0.814984005200268
  Incentive Alignment = 0.9844402502850969
Voter 2's turn.
  Best response = [2.1889002253003936e-7, 0.9999998584224982]
  New allocation: [0.5000000430414785, 0.49999994370938056]
  => Voter 2 improves by switching to best response
  Old utility = 0.8419828772437457
  New utility = 0.8574929009058266
  Honest utility = 0.8419828772437457
  Incentive Alignment = 0.9428458611892181

=== Round 2 ===
Current report matrix:
2×2 Matrix{Float64}:
 1.0        2.89963e-8
 2.1889e-7  1.0
Current allocation: [0.5000000430414785, 0.49999994370938056]
Voter 1's turn.
  => No improvement found; voter 1 stays with old report.
  Old utility = 0.8041761722113372
  New utility = 0.8041761783731818
  Honest utility = 0.7975873635748562
  Incentive Alignment = 0.9428458611892181
Voter 2's turn.
  => No improvement found; voter 2 stays with old report.
  Old utility = 0.8574929009058266
  New utility = 0.8574929405132787
  Honest utility = 0.8419828772437457
  Incentive Alignment = 0.9428458611892181
Converged! Maximum improvement in utility < 0.0001.
Final reports:
2×2 Matrix{Float64}:
 1.0        2.89963e-8
 2.1889e-7  1.0
Final Allocation: [0.5000000430414785, 0.49999994370938056]
Mean Utility: 0.8308345365585819
Optimality: 0.8308345365585819
Envy: 5.331672869448944
Incentive Alignment: 0.9428458611892181
