Optional points: [0.9615384615384615 0.038461538461538436; 0.1 0.9]
Starting allocation: [0.1, 0.038461538461538436]

=== Round 1 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.961538  0.0384615
 0.1       0.9
User 1's turn.
  Best response = [0.03396559495192303, 0.5661207932692303]
  => User 1 improves by switching to best response
  => User 1's new report: [0.03396559495192303, 0.5661207932692303]
  Old utility = 0.34854837493455965
  New utility = 0.49613893835683387
  Honest utility = 0.34854837493455965
  Incentive Alignment = 0.46642345628490733
  Allocation after user 1: [0.1, 0.9]
User 2's turn.
  => No improvement found; user 2 stays with old report.
  Old utility = 1.0
  New utility = 0.9999969722338864
  Honest utility = 1.0
  Incentive Alignment = 0.46642345628490733
  Allocation after user 2: [0.1, 0.9]

=== Round 2 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.0339656  0.566121
 0.1        0.9
User 1's turn.
  => No improvement found; user 1 stays with old report.
  Old utility = 0.49613893835683387
  New utility = 0.49613893835683387
  Honest utility = 0.34854837493455965
  Incentive Alignment = 0.46642345628490733
  Allocation after user 1: [0.1, 0.9]
User 2's turn.
  => No improvement found; user 2 stays with old report.
  Old utility = 1.0
  New utility = 0.9999969722338864
  Honest utility = 1.0
  Incentive Alignment = 0.46642345628490733
  Allocation after user 2: [0.1, 0.9]
Converged! Maximum improvement in utility < 0.0001.
Final reports:
2×2 Matrix{Float64}:
 0.0339656  0.566121
 0.1        0.9
Final Allocation: [0.1, 0.9]
Mean Utility: 0.7480694691784169
Optimality: 0.7480694691784169
Envy: 0.5038610616431661
Incentive Alignment: 0.46642345628490733
