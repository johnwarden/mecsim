Overall optimal point: [0.3, 0.3857142857142857]
Overall optimal utility: 0.6428571428571428

=== Round 1 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.8  0.1
 0.1  0.5
Current allocation: [0.45, 0.3]
Current user utilities: [0.7499999999999999, 0.37499999999999994]
Current overall optimalities: 0.8749999999999999
Voter 1's turn.
  Best response = [0.9999999751752515, 1.683429668722949e-7]
  New allocation: [0.5499999875876258, 0.25000008417148345]
  => Voter 1 improves by switching to best response
  Old utility = 0.7499999999999999
  New utility = 0.8692307208344009
  Honest utility = 0.7499999999999999
  Incentive Alignment = 0.8881966498695856
Voter 2's turn.
  Best response = [5.468577073232998e-9, 0.9999246711110352]
  New allocation: [0.4999999903219143, 0.49996241972700106]
  => Voter 2 improves by switching to best response
  Old utility = -0.01923056439664907
  New utility = 0.38461540896227536
  Honest utility = -0.01923056439664907
  Incentive Alignment = 0.6332826076456619

=== Round 2 ===
Current report matrix:
2×2 Matrix{Float64}:
 1.0         1.68343e-7
 5.46858e-9  0.999925
Current allocation: [0.4999999903219143, 0.49996241972700106]
Current user utilities: [0.615430856921955, 0.38461540896227536]
Current overall optimalities: 0.7778137623544015
Voter 1's turn.
  => No improvement found; voter 1 stays with old report.
Voter 2's turn.
  => No improvement found; voter 2 stays with old report.
Converged! Maximum improvement in utility < 1.0e-5.
Final reports:
2×2 Matrix{Float64}:
 1.0         1.68343e-7
 5.46858e-9  0.999925
Final Allocation: [0.4999999903219143, 0.49996241972700106]
Mean Utility: 0.5000231329421152
Optimality: 0.5000231329421152
Envy: 23.08154479596796
Incentive Alignment: 0.6332826076456619
