Overall optimal point: [0.3394442896071329, 0.33605209373889644, 0.32450361665397065]
Overall optimal utility: 0.8442381119645214

=== Round 1 ===
Current report matrix:
3×3 Matrix{Float64}:
 0.83819   0.136702   0.0251085
 0.04141   0.821697   0.136893
 0.127153  0.0368667  0.835981
Current allocation: [0.33558411727712495, 0.3317553366905572, 0.3326605460323179]
Current user utilities: [0.8347129663731269, 0.8533951770834125, 0.8445106007366437]
Current overall optimalities: 0.999962257211946
Voter 1's turn.
  Best response = [0.9999284591417585, 0.0006536680126288064, 2.6726975640435908e-8]
  New allocation: [0.3894214663791706, 0.2863503933997421, 0.3242281402210873]
  => Voter 1 improves by switching to best response
  Old utility = 0.8347129663731269
  New utility = 0.8593990116906477
  Honest utility = 0.8347129663731269
  Incentive Alignment = 0.9290548316827456
Voter 2's turn.
  Best response = [1.3920974279707373e-8, 0.999999773864795, 8.50447227343938e-7]
  New allocation: [0.37562073810569785, 0.3457728909515803, 0.2786063709427218]
  => Voter 2 improves by switching to best response
  Old utility = 0.8227345429476088
  New utility = 0.8530396652909448
  Honest utility = 0.8227345429476088
  Incentive Alignment = 0.8528636734526932
Voter 3's turn.
  Best response = [1.589635893138191e-5, 1.9766191751760903e-7, 0.9999999956573508]
  New allocation: [0.3332482643679108, 0.33348464055333854, 0.33326709507875063]
  => Voter 3 improves by switching to best response
  Old utility = 0.8140552221706422
  New utility = 0.8445588394420379
  Honest utility = 0.8140552221706422
  Incentive Alignment = 0.7826060073144242

=== Round 2 ===
Current report matrix:
3×3 Matrix{Float64}:
 0.999928    0.000653668  2.6727e-8
 1.3921e-8   1.0          8.50447e-7
 1.58964e-5  1.97662e-7   1.0
Current allocation: [0.3332482643679108, 0.33348464055333854, 0.33326709507875063]
Current user utilities: [0.8335015313806532, 0.854537664206026, 0.8445588394420379]
Current overall optimalities: 0.999954080543866
Voter 1's turn.
  Best response = [0.999912030501177, 7.185963810187617e-5, 1.8911448541321787e-7]
  New allocation: [0.33330922391518536, 0.3333571873635245, 0.33333358872129015]
  => Voter 1 improves by switching to best response
  Old utility = 0.8335015313806532
  New utility = 0.8335181887029873
  Honest utility = 0.8041460138304007
  Incentive Alignment = 0.7824860440258491
Voter 2's turn.
  => No improvement found; voter 2 stays with old report.
Voter 3's turn.
  => No improvement found; voter 3 stays with old report.

=== Round 3 ===
Current report matrix:
3×3 Matrix{Float64}:
 0.999912    7.18596e-5  1.89114e-7
 1.3921e-8   1.0         8.50447e-7
 1.58964e-5  1.97662e-7  1.0
Current allocation: [0.33330922391518536, 0.3333571873635245, 0.33333358872129015]
Current user utilities: [0.8335181887029873, 0.8544696735445084, 0.8446091293402171]
Current overall optimalities: 0.9999536685585942
Voter 1's turn.
  => No improvement found; voter 1 stays with old report.
Voter 2's turn.
  => No improvement found; voter 2 stays with old report.
Voter 3's turn.
  => No improvement found; voter 3 stays with old report.
Converged! Maximum improvement in utility < 1.0e-5.
Final reports:
3×3 Matrix{Float64}:
 0.999912    7.18596e-5  1.89114e-7
 1.3921e-8   1.0         8.50447e-7
 1.58964e-5  1.97662e-7  1.0
Final Allocation: [0.33330922391518536, 0.3333571873635245, 0.33333358872129015]
Mean Utility: 0.8441989971959044
Optimality: 0.8441989971959044
Envy: 2.0951484841521095
Incentive Alignment: 0.7824860440258491
