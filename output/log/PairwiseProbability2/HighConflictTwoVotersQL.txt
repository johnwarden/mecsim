Optimal points: [0.9779951100244499 0.022004889975550123; 0.058823529411764705 0.9411764705882353]
Starting allocation: [0.5, 0.5]

=== Round 1 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.977995   0.0220049
 0.0588235  0.941176
Current allocation: [0.5, 0.5]
Voter 1's turn.
  Best response = [0.29249860447120124, 0.030001402537655066]
  New allocation: [0.3306250017522141, 0.3306250017522141]
  => Voter 1 improves by switching to best response
  Old utility = 0.8041761414663255
  New utility = 0.8214352581012297
  Honest utility = 0.8041761414663255
  Incentive Alignment = 0.6572284276158278
Voter 2's turn.
  Best response = [0.2503899616074592, 0.9896101539346777]
  New allocation: [0.39062503063774834, 0.39062503063774834]
  => Voter 2 improves by switching to best response
  Old utility = 0.8616078080893901
  New utility = 0.8640331641919357
  Honest utility = 0.8616078080893901
  Incentive Alignment = 0.5584312621368893

=== Round 2 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.292499  0.0300014
 0.25039   0.98961
Current allocation: [0.39062503063774834, 0.39062503063774834]
Voter 1's turn.
  Best response = [0.05557855769050719, 0.02692132687982177]
  New allocation: [0.33062500002811646, 0.33062500002811646]
  => Voter 1 improves by switching to best response
  Old utility = 0.8189629147951557
  New utility = 0.8214352581012296
  Honest utility = 0.8041761414663255
  Incentive Alignment = 0.439988007306164
Voter 2's turn.
  Best response = [0.5627234246488804, 0.917276764214963]
  New allocation: [0.390625018358543, 0.390625018358543]
  => Voter 2 improves by switching to best response
  Old utility = 0.8616078079439448
  New utility = 0.8640331641919359
  Honest utility = 0.8533813591201096
  Incentive Alignment = 0.28655199674321824

=== Round 3 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.0555786  0.0269213
 0.562723   0.917277
Current allocation: [0.390625018358543, 0.390625018358543]
Voter 1's turn.
  Best response = [8.603107088006993e-7, 6.616530945074882e-7]
  New allocation: [0.3700004277069116, 0.3700004277069116]
  => Voter 1 improves by switching to best response
  Old utility = 0.8189629157666242
  New utility = 0.8203401768224341
  Honest utility = 0.8041761414663255
  Incentive Alignment = 0.25864594458952594
Voter 2's turn.
  Best response = [0.6940973036005514, 0.8684012982429021]
  New allocation: [0.39062503095181417, 0.39062503095181417]
  => Voter 2 improves by switching to best response
  Old utility = 0.863761842543634
  New utility = 0.8640331641919355
  Honest utility = 0.8488747799096004
  Incentive Alignment = 0.19116479741380765

=== Round 4 ===
Current report matrix:
2×2 Matrix{Float64}:
 8.60311e-7  6.61653e-7
 0.694097    0.868401
Current allocation: [0.39062503095181417, 0.39062503095181417]
Voter 1's turn.
  => No improvement found; voter 1 stays with old report.
  Old utility = 0.8189629147703084
  New utility = 0.8189629348248925
  Honest utility = 0.8041761414663255
  Incentive Alignment = 0.19116479741380765
Voter 2's turn.
  => No improvement found; voter 2 stays with old report.
  Old utility = 0.8640331641919355
  New utility = 0.8640331641919355
  Honest utility = 0.8488747799096004
  Incentive Alignment = 0.19116479741380765
Converged! Maximum improvement in utility < 0.0001.
Final reports:
2×2 Matrix{Float64}:
 8.60311e-7  6.61653e-7
 0.694097    0.868401
Final Allocation: [0.39062503095181417, 0.39062503095181417]
Mean Utility: 0.841498039481122
Optimality: 0.841498039481122
Envy: 4.507024942162719
Incentive Alignment: 0.19116479741380765
