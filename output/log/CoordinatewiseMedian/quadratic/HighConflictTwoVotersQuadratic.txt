Overall optimal point: [0.3, 0.3857142857142857]
Overall optimal utility: 0.6428571428571428

=== Round 1 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.8  0.1
 0.1  0.5
Current allocation: [0.39583333333333337, 0.3541666666666667]
Current user utilities: [0.6493055555555556, 0.5815972222222222]
Current overall optimalities: 0.9573688271604939
Voter 1's turn.
  Best response = [0.9999999390834535, 1.6959576776052233e-8]
  New allocation: [0.466666647062053, 0.33333333095946216]
  => Voter 1 improves by switching to best response
  Old utility = 0.6493055555555556
  New utility = 0.7452991268961664
  Honest utility = 0.6493055555555556
  Incentive Alignment = 0.8881966321599948
Voter 2's turn.
  Best response = [2.859544814306543e-10, 0.2002051269154697]
  New allocation: [0.3000512661509363, 0.3000512754712909]
  => Voter 2 improves by switching to best response
  Old utility = 0.37606842832001425
  New utility = 0.6923076864259602
  Honest utility = 0.37606842832001425
  Incentive Alignment = 0.7301800461076291

=== Round 2 ===
Current report matrix:
2×2 Matrix{Float64}:
 1.0          1.69596e-8
 2.85954e-10  0.200205
Current allocation: [0.3000512661509363, 0.3000512754712909]
Current user utilities: [0.5538934626231197, 0.6923076864259602]
Current overall optimalities: 0.9692675603715066
Voter 1's turn.
  => No improvement found; voter 1 stays with old report.
Voter 2's turn.
  => No improvement found; voter 2 stays with old report.
Converged! Maximum improvement in utility < 1.0e-5.
Final reports:
2×2 Matrix{Float64}:
 1.0          1.69596e-8
 2.85954e-10  0.200205
Final Allocation: [0.3000512661509363, 0.3000512754712909]
Mean Utility: 0.6231005745245399
Optimality: 0.6231005745245399
Envy: 13.841422380284051
Incentive Alignment: 0.7301800461076291
