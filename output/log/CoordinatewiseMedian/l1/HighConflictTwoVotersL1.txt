Overall optimal point: [0.530769, 0.46923075000000003]
Overall optimal utility: 0.13846175

=== Round 1 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.961538  0.0384615
 0.1       0.9
Current allocation: [0.530769, 0.46923075000000003]
Current user utilities: [0.13846175000000005, 0.13846174999999994]
Current overall optimalities: 1.0
Voter 1's turn.
  Best response = [0.9999993269823468, 1.5271291773734503e-8]
  New allocation: [0.5499996634911735, 0.4500000076356459]
  => Voter 1 improves by switching to best response
  Old utility = 0.13846175000000005
  New utility = 0.17692315585552754
  Honest utility = 0.13846175000000005
  Incentive Alignment = 0.9728036791055313
Voter 2's turn.
  Best response = [3.7220934093526e-8, 0.9999999865762679]
  New allocation: [0.4999996821016405, 0.5000000009237798]
  => Voter 2 improves by switching to best response
  Old utility = 0.10000034414447234
  New utility = 0.2000003188221393
  Honest utility = 0.10000034414447234
  Incentive Alignment = 0.9020930188924696

=== Round 2 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.999999    1.52713e-8
 3.72209e-8  1.0
Current allocation: [0.4999996821016405, 0.5000000009237798]
Current user utilities: [0.07692318117786057, 0.2000003188221393]
Current overall optimalities: 0.9999999999999996
Voter 1's turn.
  => No improvement found; voter 1 stays with old report.
Voter 2's turn.
  => No improvement found; voter 2 stays with old report.
Converged! Maximum improvement in utility < 1.0e-5.
Final reports:
2×2 Matrix{Float64}:
 0.999999    1.52713e-8
 3.72209e-8  1.0
Final Allocation: [0.4999996821016405, 0.5000000009237798]
Mean Utility: 0.13846174999999994
Optimality: 0.13846174999999994
Envy: 12.307713764427874
Incentive Alignment: 0.9020930188924696
