Overall optimal point: [0.3, 0.3857142857142857]
Overall optimal utility: 0.6428571428571428

=== Round 1 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.8  0.1
 0.1  0.5
Current allocation: [0.3854247166457143, 0.3645752833542857]
Current user utilities: [0.6278880828764818, 0.6161264509582373]
Current overall optimalities: 0.9675668596492261
Voter 1's turn.
  Best response = [0.9999997927990338, 1.467986456530389e-7]
  New allocation: [0.43356804040642744, 0.36643192939241237]
  => Voter 1 improves by switching to best response
  Old utility = 0.6278880828764818
  New utility = 0.6842179169056168
  Honest utility = 0.6278880828764818
  Incentive Alignment = 0.888196726613273
Voter 2's turn.
  Best response = [3.738786022866251e-9, 0.1999699350358729]
  New allocation: [0.29999245037827976, 0.29999248880788937]
  => Voter 2 improves by switching to best response
  Old utility = 0.5034305112830095
  New utility = 0.6923077509939577
  Honest utility = 0.5034305112830095
  Incentive Alignment = 0.7300685830598395

=== Round 2 ===
Current report matrix:
2×2 Matrix{Float64}:
 1.0         1.46799e-7
 3.73879e-9  0.19997
Current allocation: [0.29999245037827976, 0.29999248880788937]
Current user utilities: [0.553839161141091, 0.6923077509939577]
Current overall optimalities: 0.969225376105038
Voter 1's turn.
  => No improvement found; voter 1 stays with old report.
Voter 2's turn.
  => No improvement found; voter 2 stays with old report.
Converged! Maximum improvement in utility < 1.0e-5.
Final reports:
2×2 Matrix{Float64}:
 1.0         1.46799e-7
 3.73879e-9  0.19997
Final Allocation: [0.29999245037827976, 0.29999248880788937]
Mean Utility: 0.6230734560675244
Optimality: 0.6230734560675244
Envy: 13.84685898528667
Incentive Alignment: 0.7300685830598395
