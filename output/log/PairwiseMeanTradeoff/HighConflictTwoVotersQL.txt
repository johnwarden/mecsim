Optimal points: [0.9779951100244499 0.022004889975550123; 0.058823529411764705 0.9411764705882353]
Starting allocation: [0.5092077814625776, 0.4907922185374223]

=== Round 1 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.977995   0.0220049
 0.0588235  0.941176
Current allocation: [0.5092077814625776, 0.4907922185374223]
Voter 1's turn.
  Best response = [0.9753263042977851, 1.6577200270824664e-8]
  New allocation: [0.5147186215012286, 0.48528137849877145]
  => Voter 1 improves by switching to best response
  Old utility = 0.8096153025621446
  New utility = 0.8128385754363855
  Honest utility = 0.8096153025621446
  Incentive Alignment = 0.988916938856028
Voter 2's turn.
  Best response = [6.126083089899119e-8, 0.752913406725227]
  New allocation: [0.5000000160921169, 0.4999999839078832]
  => Voter 2 improves by switching to best response
  Old utility = 0.8498265289877097
  New utility = 0.8574929174332183
  Honest utility = 0.8498265289877097
  Incentive Alignment = 0.8902974914579729

=== Round 2 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.975326    1.65772e-8
 6.12608e-8  0.752913
Current allocation: [0.5000000160921169, 0.4999999839078832]
Voter 1's turn.
  => No improvement found; voter 1 stays with old report.
  Old utility = 0.8041761510313358
  New utility = 0.8041761510313358
  Honest utility = 0.8008936587707743
  Incentive Alignment = 0.8902974914579729
Voter 2's turn.
  => No improvement found; voter 2 stays with old report.
  Old utility = 0.8574929174332183
  New utility = 0.8574929174332183
  Honest utility = 0.8498265289877097
  Incentive Alignment = 0.8902974914579729
Converged! Maximum improvement in utility < 0.0001.
Final reports:
2×2 Matrix{Float64}:
 0.975326    1.65772e-8
 6.12608e-8  0.752913
Final Allocation: [0.5000000160921169, 0.4999999839078832]
Mean Utility: 0.830834534232277
Optimality: 0.830834534232277
Envy: 5.331676640188254
Incentive Alignment: 0.8902974914579729
