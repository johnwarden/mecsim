Optimal points: [0.8333333333333333 0.13333333333333336 0.033333333333333305; 0.782608695652174 0.19565217391304346 0.021739130434782566; 0.7619047619047619 0.19047619047619044 0.04761904761904763]
Starting allocation: [0.8787878787878789, 0.08787878787878795, 0.033333333333333354]

=== Round 1 ===
Current report matrix:
3×3 Matrix{Float64}:
 0.833333  0.133333  0.0333333
 0.782609  0.195652  0.0217391
 0.761905  0.190476  0.047619
Current allocation: [0.8787878787878789, 0.08787878787878795, 0.033333333333333354]
Voter 1's turn.
  => No improvement found; voter 1 stays with old report.
  Old utility = 0.9973380822055828
  New utility = 0.9973380822055828
  Honest utility = 0.9973380822055828
  Incentive Alignment = 1.0
Voter 2's turn.
  => No improvement found; voter 2 stays with old report.
  Old utility = 0.9873489051913094
  New utility = 0.9873489051913094
  Honest utility = 0.9873489051913094
  Incentive Alignment = 1.0
Voter 3's turn.
  => No improvement found; voter 3 stays with old report.
  Old utility = 0.9874815137804089
  New utility = 0.9874815137804089
  Honest utility = 0.9874815137804089
  Incentive Alignment = 1.0
Converged! Maximum improvement in utility < 0.0001.
Final reports:
3×3 Matrix{Float64}:
 0.833333  0.133333  0.0333333
 0.782609  0.195652  0.0217391
 0.761905  0.190476  0.047619
Final Allocation: [0.8787878787878789, 0.08787878787878795, 0.033333333333333354]
Mean Utility: 0.9907228337257671
Optimality: 0.9907228337257671
Envy: 0.9989177014273487
Incentive Alignment: 1.0
