Overall optimal point: [0.5620173672946042, 0.43798263270539584]
Overall optimal utility: 0.8649100931185952

=== Round 1 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.961538  0.0384615
 0.1       0.9
Current allocation: [0.5620173672946043, 0.43798263270539567]
Current user utilities: [0.8649100931185952, 0.8649100931185951]
Current overall optimalities: 0.9999999999999999
Voter 1's turn.
  Best response = [0.9999998309707226, 6.485668652040191e-15]
  New allocation: [0.6581138159135697, 0.34188618408643034]
  => Voter 1 improves by switching to best response
  Old utility = 0.8649100931185952
  New utility = 0.9101595019941812
  Honest utility = 0.8649100931185952
  Incentive Alignment = 0.9728036450997897
Voter 2's turn.
  Best response = [1.2844620401495334e-13, 0.9999998776954344]
  New allocation: [0.5000001272489394, 0.4999998727510606]
  => Voter 2 improves by switching to best response
  Old utility = 0.8112422265287139
  New utility = 0.894427134092453
  Honest utility = 0.8112422265287139
  Incentive Alignment = 0.902093010222361

=== Round 2 ===
Current report matrix:
2×2 Matrix{Float64}:
 1.0          6.48567e-15
 1.28446e-13  1.0
Current allocation: [0.5000001272489394, 0.4999998727510606]
Current user utilities: [0.8320503649228487, 0.894427134092453]
Current overall optimalities: 0.9980676100045056
Voter 1's turn.
  => No improvement found; voter 1 stays with old report.
Voter 2's turn.
  => No improvement found; voter 2 stays with old report.
Converged! Maximum improvement in utility < 1.0e-5.
Final reports:
2×2 Matrix{Float64}:
 1.0          6.48567e-15
 1.28446e-13  1.0
Final Allocation: [0.5000001272489394, 0.4999998727510606]
Mean Utility: 0.8632387495076508
Optimality: 0.8632387495076508
Envy: 6.237676916960433
Incentive Alignment: 0.902093010222361
