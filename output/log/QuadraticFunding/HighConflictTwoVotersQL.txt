Optimal points: [0.9779951100244499 0.022004889975550123; 0.058823529411764705 0.9411764705882353]
Starting allocation: [0.5479704592928129, 0.45202954070718715]

=== Round 1 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.977995   0.0220049
 0.0588235  0.941176
Current allocation: [0.5479704592928129, 0.45202954070718715]
Voter 1's turn.
  Best response = [0.9999998157129901, 1.4300240855521514e-14]
  New allocation: [0.6212677196138783, 0.3787322803861219]
  => Voter 1 improves by switching to best response
  Old utility = 0.831794347883689
  New utility = 0.8707754899791028
  Honest utility = 0.831794347883689
  Incentive Alignment = 0.9844402582341905
Voter 2's turn.
  Best response = [5.213995450766485e-15, 0.9999954647188694]
  New allocation: [0.5000010640631605, 0.49999893593683953]
  => Voter 2 improves by switching to best response
  Old utility = 0.7882054969501611
  New utility = 0.8574923782560792
  Honest utility = 0.7882054969501611
  Incentive Alignment = 0.9428473451269204

=== Round 2 ===
Current report matrix:
2×2 Matrix{Float64}:
 1.0        1.43002e-14
 5.214e-15  0.999995
Current allocation: [0.5000010640631605, 0.49999893593683953]
Voter 1's turn.
  => No improvement found; voter 1 stays with old report.
  Old utility = 0.8041767739355012
  New utility = 0.8041767954894322
  Honest utility = 0.7577408711430289
  Incentive Alignment = 0.9428473451269204
Voter 2's turn.
  => No improvement found; voter 2 stays with old report.
  Old utility = 0.8574923782560792
  New utility = 0.8574923947324853
  Honest utility = 0.7882054969501611
  Incentive Alignment = 0.9428473451269204
Converged! Maximum improvement in utility < 0.0001.
Final reports:
2×2 Matrix{Float64}:
 1.0        1.43002e-14
 5.214e-15  0.999995
Final Allocation: [0.5000010640631605, 0.49999893593683953]
Mean Utility: 0.8308345760957903
Optimality: 0.8308345760957903
Envy: 5.331560432057792
Incentive Alignment: 0.9428473451269204
