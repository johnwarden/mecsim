Optional points: [0.3083700440528634 0.3303964757709251 0.36123348017621143; 0.3435114503816794 0.3129770992366412 0.3435114503816794; 0.3478260869565218 0.30434782608695654 0.3478260869565218]
Starting allocation: [0.32248545138177465, 0.31827911940722986, 0.3592354292109955]

=== Round 1 ===
Current report matrix:
3×3 Matrix{Float64}:
 0.30837   0.330396  0.361233
 0.343511  0.312977  0.343511
 0.347826  0.304348  0.347826
User 1's turn.
  Best response = [0.24714443005116882, 0.44330704517231895, 0.46235970560628936]
  => User 1 improves by switching to best response
  => User 1's new report: [0.24714443005116882, 0.44330704517231895, 0.46235970560628936]
  Old utility = 0.9989060828704167
  New utility = 1.001628523162747
  Honest utility = 0.9989060828704167
  Incentive Alignment = 0.9455085266994648
  Allocation after user 1: [0.2761378844029401, 0.34005202868980733, 0.38381008690725255]
User 2's turn.
  Best response = [0.41040002726659236, 0.27555773499649955, 0.33017352245416676]
  => User 2 improves by switching to best response
  => User 2's new report: [0.41040002726659236, 0.27555773499649955, 0.33017352245416676]
  Old utility = 0.9932379954721529
  New utility = 1.0005240289729316
  Honest utility = 0.9932379954721529
  Incentive Alignment = 0.9195765840220451
  Allocation after user 2: [0.3478260869565218, 0.30434782608695654, 0.3478260869565218]
User 3's turn.
  Best response = [0.3622198859647242, 0.1413334061527449, 0.3622163235843238]
  => User 3 improves by switching to best response
  => User 3's new report: [0.3622198859647242, 0.1413334061527449, 0.3622163235843238]
  Old utility = 1.0
  New utility = 1.0016696736844082
  Honest utility = 1.0
  Incentive Alignment = 0.8648165403298093
  Allocation after user 3: [0.36222207938402756, 0.2755594036339172, 0.3622185169820552]

=== Round 2 ===
Current report matrix:
3×3 Matrix{Float64}:
 0.247144  0.443307  0.46236
 0.4104    0.275558  0.330174
 0.36222   0.141333  0.362216
User 1's turn.
  => No improvement found; user 1 stays with old report.
  Old utility = 0.9925368030917752
  New utility = 0.9925368030917752
  Honest utility = 0.9924717473324036
  Incentive Alignment = 0.8648165403298093
  Allocation after user 1: [0.36222207938402756, 0.2755594036339172, 0.3622185169820552]
User 2's turn.
  => No improvement found; user 2 stays with old report.
  Old utility = 1.0011311374224054
  New utility = 1.0011311374224057
  Honest utility = 0.9870286370206205
  Incentive Alignment = 0.8648165403298093
  Allocation after user 2: [0.36222207938402756, 0.2755594036339172, 0.3622185169820552]
User 3's turn.
  => No improvement found; user 3 stays with old report.
  Old utility = 1.0016696736844082
  New utility = 1.0016696736893242
  Honest utility = 1.0
  Incentive Alignment = 0.8648165403298093
  Allocation after user 3: [0.36222207938402756, 0.2755594036339172, 0.3622185169820552]
Converged! Maximum improvement in utility < 0.0001.
Final reports:
3×3 Matrix{Float64}:
 0.247144  0.443307  0.46236
 0.4104    0.275558  0.330174
 0.36222   0.141333  0.362216
Final Allocation: [0.36222207938402756, 0.2755594036339172, 0.3622185169820552]
Mean Utility: 0.9984458713995297
Optimality: 0.9984458713995297
Envy: 0.009132870592633013
Incentive Alignment: 0.8648165403298093
