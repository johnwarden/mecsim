Optional points: [0.9615384615384615 0.038461538461538436; 0.1 0.9]
Starting allocation: [0.7222222222222223, 0.2777777777777776]

=== Round 1 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.961538  0.0384615
 0.1       0.9
User 1's turn.
  Best response = [0.6501153008295943, 0.004000002469221886]
  => User 1 improves by switching to best response
  => User 1's new report: [0.6501153008295943, 0.004000002469221886]
  Old utility = 0.9366956121576738
  New utility = 0.9999999999999982
  Honest utility = 0.9366956121576738
  Incentive Alignment = 0.8433379573023106
  Allocation after user 1: [0.9615384387091177, 0.038461561290882275]
User 2's turn.
  Best response = [0.00044446946982241835, 0.7493464726765521]
  => User 2 improves by switching to best response
  => User 2's new report: [0.00044446946982241835, 0.7493464726765521]
  Old utility = 0.4961389898925208
  New utility = 0.999999999965111
  Honest utility = 0.4961389898925208
  Incentive Alignment = 0.7530498227632945
  Allocation after user 2: [0.10000501205054131, 0.8999949879494588]

=== Round 2 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.650115     0.004
 0.000444469  0.749346
User 1's turn.
  Best response = [0.7921436981961405, 1.8332850575548434e-5]
  => User 1 improves by switching to best response
  => User 1's new report: [0.7921436981961405, 1.8332850575548434e-5]
  Old utility = 0.4961461910562627
  New utility = 0.9999955840652756
  Honest utility = 0.2998010526263031
  Incentive Alignment = 0.8228607487360854
  Allocation after user 1: [0.9603872976268055, 0.03961270237319444]
User 2's turn.
  Best response = [2.038719921597421e-6, 0.7522838974114304]
  => User 2 improves by switching to best response
  => User 2's new report: [2.038719921597421e-6, 0.7522838974114304]
  Old utility = 0.49871702961703274
  New utility = 0.99999999182821
  Honest utility = 0.329042669404279
  Incentive Alignment = 0.8239585821990754
  Allocation after user 2: [0.10007671828163933, 0.8999232817183607]

=== Round 3 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.792144    1.83329e-5
 2.03872e-6  0.752284
User 1's turn.
  Best response = [0.5037848470276326, 8.145711181589389e-8]
  => User 1 improves by switching to best response
  => User 1's new report: [0.5037848470276326, 8.145711181589389e-8]
  Old utility = 0.4962499322529774
  New utility = 0.9999999941530651
  Honest utility = 0.20324993589513277
  Incentive Alignment = 0.6811264086781268
  Allocation after user 1: [0.9615800423586541, 0.03841995764134586]
User 2's turn.
  Best response = [0.011002799841663708, 0.49620909751791514]
  => User 2 improves by switching to best response
  => User 2's new report: [0.011002799841663708, 0.49620909751791514]
  Old utility = 0.49604504520676107
  New utility = 0.8927267626890535
  Honest utility = 0.31708385764281644
  Incentive Alignment = 0.5635755705466168
  Allocation after user 2: [0.5037878976923007, 0.49621210230769935]

=== Round 4 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.503785   8.14571e-8
 0.0110028  0.496209
User 1's turn.
  Best response = [0.7384660885886462, 0.0004401344249138971]
  => User 1 improves by switching to best response
  => User 1's new report: [0.7384660885886462, 0.0004401344249138971]
  Old utility = 0.8341454876990813
  New utility = 0.9999999999879922
  Honest utility = 0.6354096758751504
  Incentive Alignment = 0.6801141407009171
  Allocation after user 1: [0.9615365766629074, 0.03846342333709255]
User 2's turn.
  Best response = [4.9128601225395195e-5, 0.6818009866393194]
  => User 2 improves by switching to best response
  => User 2's new report: [4.9128601225395195e-5, 0.6818009866393194]
  Old utility = 0.49614319327954337
  New utility = 0.9999997629872132
  Honest utility = 0.37833423337408567
  Incentive Alignment = 0.7668542526993615
  Allocation after user 2: [0.10041347618899853, 0.8995865238110015]

=== Round 5 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.738466    0.000440134
 4.91286e-5  0.681801
User 1's turn.
  Best response = [0.7412769087002787, 1.965299748897807e-6]
  => User 1 improves by switching to best response
  => User 1's new report: [0.7412769087002787, 1.965299748897807e-6]
  Old utility = 0.4967366019239196
  New utility = 0.9999999999709818
  Honest utility = 0.23101453866202254
  Incentive Alignment = 0.7682019575954269
  Allocation after user 1: [0.9615355314152542, 0.03846446858474582]
User 2's turn.
  Best response = [2.1845077106555695e-7, 0.6820668621327706]
  => User 2 improves by switching to best response
  => User 2's new report: [2.1845077106555695e-7, 0.6820668621327706]
  Old utility = 0.49614555277589
  New utility = 0.9999999983304283
  Honest utility = 0.320430291793553
  Incentive Alignment = 0.7683126089495838
  Allocation after user 2: [0.10003467386431204, 0.899965326135688]

=== Round 6 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.741277    1.9653e-6
 2.18451e-7  0.682067
User 1's turn.
  Best response = [0.7412884354355647, 8.741840763310899e-9]
  => User 1 improves by switching to best response
  => User 1's new report: [0.7412884354355647, 8.741840763310899e-9]
  Old utility = 0.4961891092378267
  New utility = 0.9999999991213698
  Honest utility = 0.19845250743509638
  Incentive Alignment = 0.7683181181319672
  Allocation after user 1: [0.961522336959198, 0.038477663040801975]
User 2's turn.
  Best response = [9.715321728519854e-10, 0.6820680475409219]
  => User 2 improves by switching to best response
  => User 2's new report: [9.715321728519854e-10, 0.6820680475409219]
  Old utility = 0.49617533440314254
  New utility = 0.9999999994409898
  Honest utility = 0.3165082456171436
  Incentive Alignment = 0.7683186114818306
  Allocation after user 2: [0.10002006298295944, 0.8999799370170406]

=== Round 7 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.741288     8.74184e-9
 9.71532e-10  0.682068
User 1's turn.
  Best response = [0.7412884867108345, 3.8780970646101986e-11]
  => User 1 improves by switching to best response
  => User 1's new report: [0.7412884867108345, 3.8780970646101986e-11]
  Old utility = 0.49616796936416024
  New utility = 0.9999999802321392
  Honest utility = 0.1962719797135443
  Incentive Alignment = 0.7683186359887157
  Allocation after user 1: [0.9616149003943197, 0.03838509960568023]
User 2's turn.
  Best response = [4.309252349029104e-12, 0.6820680528129685]
  => User 2 improves by switching to best response
  => User 2's new report: [4.309252349029104e-12, 0.6820680528129685]
  Old utility = 0.495966290629715
  New utility = 0.999999999960414
  Honest utility = 0.3162464482662891
  Incentive Alignment = 0.7683186381828648
  Allocation after user 2: [0.10000533878685244, 0.8999946612131476]

=== Round 8 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.741288     3.8781e-11
 4.30925e-12  0.682068
User 1's turn.
  Best response = [0.7412884869383028, 1.7235278799153154e-13]
  => User 1 improves by switching to best response
  => User 1's new report: [0.7412884869383028, 1.7235278799153154e-13]
  Old utility = 0.4961466638539929
  New utility = 0.9999999999533992
  Honest utility = 0.19612651449657695
  Incentive Alignment = 0.7683186382915828
  Allocation after user 1: [0.9615421745731684, 0.038457825426831654]
User 2's turn.
  Best response = [1.9162310247037918e-14, 0.6820680528363525]
  => User 2 improves by switching to best response
  => User 2's new report: [1.9162310247037918e-14, 0.6820680528363525]
  Old utility = 0.4961305562155066
  New utility = 0.9999999955839481
  Honest utility = 0.3162290114783641
  Incentive Alignment = 0.768318638301315
  Allocation after user 2: [0.1000563946303989, 0.8999436053696012]

=== Round 9 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.741288     1.72353e-13
 1.91623e-14  0.682068
User 1's turn.
  Best response = [0.7412884869393139, 7.650684085781106e-16]
  => User 1 improves by switching to best response
  => User 1's new report: [0.7412884869393139, 7.650684085781106e-16]
  Old utility = 0.4962205330268279
  New utility = 0.999999984028595
  Honest utility = 0.19611682727811824
  Incentive Alignment = 0.7683186383017981
  Allocation after user 1: [0.961607172634194, 0.038392827365805855]
User 2's turn.
  Best response = [8.497727046668258e-17, 0.6820680528364564]
  => User 2 improves by switching to best response
  => User 2's new report: [8.497727046668258e-17, 0.6820680528364564]
  Old utility = 0.4959837532305088
  New utility = 0.9999999985675195
  Honest utility = 0.3162278489964468
  Incentive Alignment = 0.7683186383018414
  Allocation after user 2: [0.09996788709304727, 0.9000321129069527]

=== Round 10 ===
Current report matrix:
2×2 Matrix{Float64}:
 0.741288     7.65068e-16
 8.49773e-17  0.682068
User 1's turn.
  Best response = [0.7412884869393181, 3.398443681504341e-18]
  => User 1 improves by switching to best response
  => User 1's new report: [0.7412884869393181, 3.398443681504341e-18]
  Old utility = 0.49609246464402185
  New utility = 0.9999999998324228
  Honest utility = 0.1961161812297423
  Incentive Alignment = 0.7683186383018434
  Allocation after user 1: [0.9615455024690845, 0.03845449753091542]
User 2's turn.
  Best response = [3.777129648407649e-19, 0.6820680528364569]
  => User 2 improves by switching to best response
  => User 2's new report: [3.777129648407649e-19, 0.6820680528364569]
  Old utility = 0.49612304315200845
  New utility = 0.9999999990779697
  Honest utility = 0.3162277715472985
  Incentive Alignment = 0.7683186383018435
  Allocation after user 2: [0.10002576699416019, 0.8999742330058398]
Final reports:
2×2 Matrix{Float64}:
 0.741288     3.39844e-18
 3.77713e-19  0.682068
Final Allocation: [0.10002576699416019, 0.8999742330058398]
Mean Utility: 0.7480881107679397
Optimality: 0.7480881107679397
Envy: 0.50382377662006
Incentive Alignment: 0.7683186383018435
